{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Started\n",
    "\n",
    "*by [Longqi@Cornell](http://www.cs.cornell.edu/~ylongqi/) licensed under [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/)*\n",
    "\n",
    "This tutorial demonstrates the process of training and evaluating recommendation algorithms using OpenRec (tutorial on implementing new recommendation algorithm: [tutorial]()):\n",
    " * Prepare training and evaluation datasets.\n",
    " * Instantiate a recommender.\n",
    " * Instantiate a sampler.\n",
    " * Instantiate evaluators.\n",
    " * Instantiate a model trainer.\n",
    " * TRAIN AND EVALUATE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training and evaluation datasets\n",
    "\n",
    "* Download your favorite dataset from the web. In this tutorial, we use [a relatively small citeulike dataset](http://www.wanghao.in/CDL.htm) for demonstration purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "urllib.urlretrieve('http://www.wanghao.in/data/ctrsr_datasets.rar', 'ctrsr_datasets.rar')\n",
    "os.system('unrar x ctrsr_datasets.rar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert raw data into structured numpy array. As required by the **[Dataset](http://openrec.readthedocs.io/en/latest/utils/openrec.utils.dataset.html)** class, two keys `user_id` and `item_id` are required. Each row in the converted numpy array represents an interaction. The array might contain additional keys based on the use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "users_count = 0\n",
    "interactions_count = 0\n",
    "with open('ctrsr_datasets/citeulike-a/users.dat', 'r') as fin:\n",
    "    for line in fin:\n",
    "        interactions_count += int(line.split()[0])\n",
    "        users_count += 1\n",
    "\n",
    "# radomly hold out an item per user for validation and testing respectively.\n",
    "val_structured_arr = np.zeros(users_count, dtype=[('user_id', np.int32), ('item_id', np.int32)]) \n",
    "test_structured_arr = np.zeros(users_count, dtype=[('user_id', np.int32), ('item_id', np.int32)])\n",
    "train_structured_arr = np.zeros(interactions_count-11102, dtype=[('user_id', np.int32), ('item_id', np.int32)])\n",
    "\n",
    "interaction_ind = 0\n",
    "next_user_id = 0\n",
    "next_item_id = 0\n",
    "map_to_item_id = dict()  # Map item id from 0 to len(items)-1\n",
    "\n",
    "with open('ctrsr_datasets/citeulike-a/users.dat', 'r') as fin:\n",
    "    for line in fin:\n",
    "        item_list = line.split()[1:]\n",
    "        random.shuffle(item_list)\n",
    "        for ind, item in enumerate(item_list):\n",
    "            if item not in map_to_item_id:\n",
    "                map_to_item_id[item] = next_item_id\n",
    "                next_item_id += 1\n",
    "            if ind == 0:\n",
    "                val_structured_arr[next_user_id] = (next_user_id, map_to_item_id[item])\n",
    "            elif ind == 1:\n",
    "                test_structured_arr[next_user_id] = (next_user_id, map_to_item_id[item])\n",
    "            else:\n",
    "                train_structured_arr[interaction_ind] = (next_user_id, map_to_item_id[item])\n",
    "                interaction_ind += 1\n",
    "        next_user_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instantiate training, validation, and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openrec.utils import Dataset\n",
    "\n",
    "train_dataset = Dataset(raw_data=train_structured_arr, \n",
    "                        max_user=users_count, \n",
    "                        max_item=len(map_to_item_id), name='Train')\n",
    "val_dataset = Dataset(raw_data=val_structured_arr, \n",
    "                      max_user=users_count,\n",
    "                      max_item=len(map_to_item_id), name='Val')\n",
    "test_dataset = Dataset(raw_data=test_structured_arr, \n",
    "                       max_user=users_count,\n",
    "                       max_item=len(map_to_item_id), name='Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate a recommender\n",
    "\n",
    "We use the [BPR recommender](http://openrec.readthedocs.io/en/latest/recommenders/openrec.recommenders.bpr.html) that implements the pure Baysian Personalized Ranking (BPR) algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openrec.recommenders import BPR\n",
    "\n",
    "bpr_model = BPR(batch_size=1000, \n",
    "                max_user=train_dataset.max_user(), \n",
    "                max_item=train_dataset.max_item(), \n",
    "                dim_embed=20, \n",
    "                opt='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate a sampler\n",
    "\n",
    "A basic [pairwise sampler](http://openrec.readthedocs.io/en/latest/utils/openrec.utils.samplers.html) is used, i.e., each instance contains an user, an item that the user interacts, and an item that the user did NOT interact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openrec.utils.samplers import PairwiseSampler\n",
    "\n",
    "sampler = PairwiseSampler(batch_size=1000, dataset=train_dataset, num_process=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate evaluators\n",
    "\n",
    "Define evaluators that you plan to use. This tutorial evaluate the recommender against Area Under Curve (AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openrec.utils.evaluators import AUC\n",
    "\n",
    "auc_evaluator = AUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate a model trainer\n",
    "\n",
    "The [model trainer](http://openrec.readthedocs.io/en/latest/openrec.model_trainer.html) drives the training and evaluation of the recommender using defined datasets, sampler, model, and evaluators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openrec import ModelTrainer\n",
    "\n",
    "model_trainer = ModelTrainer(batch_size=1000, \n",
    "                             test_batch_size=100, \n",
    "                            train_dataset=train_dataset, \n",
    "                             model=bpr_model, \n",
    "                             sampler=sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN AND EVALUATE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m== Start training with FULL evaluation ==\u001b[0m\n",
      "\u001b[31m[Itr 1000]\u001b[0m loss: 574.760079\n",
      "\u001b[32m..(dataset: Val) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:36<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Val)\u001b[0m AUC 0.863639218489\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 56/56 [00:36<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.862847245582\n",
      "\u001b[31m[Itr 2000]\u001b[0m loss: 285.225980\n",
      "\u001b[32m..(dataset: Val) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:34<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Val)\u001b[0m AUC 0.907307552971\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 56/56 [00:33<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.907252630409\n",
      "\u001b[31m[Itr 3000]\u001b[0m loss: 177.170356\n",
      "\u001b[32m..(dataset: Val) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:34<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Val)\u001b[0m AUC 0.925500286845\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 56/56 [00:34<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.925240806309\n",
      "\u001b[31m[Itr 4000]\u001b[0m loss: 129.689745\n",
      "\u001b[32m..(dataset: Val) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:32<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Val)\u001b[0m AUC 0.935238305499\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 56/56 [00:33<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.935054893445\n",
      "\u001b[31m[Itr 5000]\u001b[0m loss: 102.001850\n",
      "\u001b[32m..(dataset: Val) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:33<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Val)\u001b[0m AUC 0.941553772344\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 56/56 [00:33<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.940910863792\n",
      "\u001b[31m[Itr 6000]\u001b[0m loss: 84.294602\n",
      "\u001b[32m..(dataset: Val) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:33<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Val)\u001b[0m AUC 0.945139484312\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 56/56 [00:33<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.944559871769\n",
      "\u001b[31m[Itr 7000]\u001b[0m loss: 71.964525\n",
      "\u001b[32m..(dataset: Val) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:32<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Val)\u001b[0m AUC 0.947785507114\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 56/56 [00:32<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.947331528684\n",
      "\u001b[31m[Itr 8000]\u001b[0m loss: 62.937360\n",
      "\u001b[32m..(dataset: Val) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:33<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Val)\u001b[0m AUC 0.949624674929\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 56/56 [00:32<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.948953140753\n",
      "\u001b[31m[Itr 9000]\u001b[0m loss: 56.139020\n",
      "\u001b[32m..(dataset: Val) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:33<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Val)\u001b[0m AUC 0.950871574159\n",
      "\u001b[32m..(dataset: Test) evaluation\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 56/56 [00:33<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m..(dataset: Test)\u001b[0m AUC 0.95021441687\n"
     ]
    }
   ],
   "source": [
    "model_trainer.train(num_itr=10000, \n",
    "                    display_itr=1000, \n",
    "                    eval_datasets=[val_dataset, test_dataset],\n",
    "                    evaluators=[auc_evaluator])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openrec",
   "language": "python",
   "name": "openrec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
