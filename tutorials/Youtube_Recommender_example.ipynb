{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Youtube Recommender example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ylongqi/openrec/blob/master/tutorials/Youtube_Recommender_example.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "jWlLsq0c83u9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img src =\"https://recsys.acm.org/wp-content/uploads/2017/07/recsys-18-small.png\" height=\"40\" /> <font size=\"4\">Recsys 2018 Tutorial</font>\n",
        "</p>\n",
        "<p align=\"center\">\n",
        "  <font size=\"4\"><b>Modularizing Deep Neural Network-Inspired Recommendation Algorithms</b></font>\n",
        "</p>\n",
        "<p align=\"center\">\n",
        "  <font size=\"4\">Hands on: Customizing Deep YouTube Video Recommendation. Youtube example</font>\n",
        "</p>"
      ]
    },
    {
      "metadata": {
        "id": "xXV-a9jCQtvh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# the Youtube Recommender\n",
        "\n",
        "The training graph of YouTube-Rec can be decomposed as follows.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src =\"https://s3.amazonaws.com/cornell-tech-sdl-openrec/tutorials/youtube_rec_module.png\" height=\"400\" />\n",
        "</p>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* **inputgraph**: user demographis, item consumption history and the groundtruth label.\n",
        "* **usergraph**: extract user-specific latent factor.\n",
        "* **itemgraph**: extract latent factors for items.\n",
        "* **interactiongraph**: uses MLP and softmax to model user-item interactions.\n",
        "\n",
        "After defining subgraphs, their interfaces and connections need to be specified. A sample specification of YouTube-Rec can be as follows.\n",
        "<p align=\"center\">\n",
        "  <img src =\"https://s3.amazonaws.com/cornell-tech-sdl-openrec/tutorials/youtube_rec.png\" height=\"300\" />\n",
        "</p>"
      ]
    },
    {
      "metadata": {
        "id": "fx9f__-hL3C2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install OpenRec and download dataset"
      ]
    },
    {
      "metadata": {
        "id": "iCPtcmnDKsBH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install openrec\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "dataset_prefix = 'http://s3.amazonaws.com/cornell-tech-sdl-openrec'\n",
        "urllib.request.urlretrieve('%s/lastfm/lastfm_test.npy' % dataset_prefix, \n",
        "                   'lastfm_test.npy')\n",
        "urllib.request.urlretrieve('%s/lastfm/lastfm_train.npy' % dataset_prefix, \n",
        "                   'lastfm_train.npy')\n",
        "urllib.request.urlretrieve('%s/lastfm/user_feature.npy' % dataset_prefix, \n",
        "                   'user_feature.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xoTTS6s0OJMu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Your task \n",
        "-  understand reuse and extend an exsiting recommender\n",
        "-  fill in the placeholders in the implementation of the `YouTubeRec` function \n",
        "-  successfully run the experimental code with the recommender you just built. "
      ]
    },
    {
      "metadata": {
        "id": "DybVedLuNe_d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from openrec.recommenders import VanillaYouTubeRec  # load the vanilla version and extend it with user demographic informaton\n",
        "from openrec.modules.extractions import LatentFactor\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def Tutorial_YouTubeRec(batch_size, user_dict, item_dict, dim_user_embed, dim_item_embed, \n",
        "        max_seq_len, l2_reg_embed=None, l2_reg_mlp=None, dropout=None, \n",
        "        init_model_dir=None, save_model_dir='Youtube/', train=True, serve=False):\n",
        "\n",
        "  \n",
        "    rec = VanillaYouTubeRec(batch_size=batch_size,\n",
        "                            dim_item_embed=dim_item_embed['id'], \n",
        "                            max_seq_len=max_seq_len, \n",
        "                            total_items=item_dict['id'],\n",
        "                            l2_reg_embed=l2_reg_embed, \n",
        "                            l2_reg_mlp=l2_reg_embed, \n",
        "                            dropout=dropout, \n",
        "                            init_model_dir=init_model_dir,\n",
        "                            save_model_dir=save_model_dir, \n",
        "                            train=train, \n",
        "                            serve=serve)\n",
        "    \n",
        "\n",
        "    #TODO: fill in training inputgraph extension\n",
        "    @rec.traingraph.inputgraph.extend(outs=['FILL_IN_VARIABLE', 'FILL_IN_VARIABLE'])\n",
        "    def add_feature(subgraph):\n",
        "        subgraph['FILL_IN_VARIABLE'] = tf.placeholder(tf.int32, shape=[batch_size], name='FILL_IN_VARIABLE')\n",
        "        subgraph['FILL_IN_VARIABLE'] = tf.placeholder(tf.int32, shape=[batch_size], name='FILL_IN_VARIABLE')\n",
        "       \n",
        "        subgraph.update_global_input_mapping({'FILL_IN_VARIABLE': subgraph['FILL_IN_VARIABLE'],\n",
        "                                              'FILL_IN_VARIABLE': subgraph['FILL_IN_VARIABLE']})\n",
        "\n",
        "        \n",
        "     #TODO: fill in serve inputgraph extension [Hint: similar to training graph]\n",
        "    @rec.servegraph.inputgraph.extend(outs=['FILL_IN_VARIABLE', 'FILL_IN_VARIABLE'])\n",
        "    def add_feature(subgraph):\n",
        "        subgraph['FILL_IN_VARIABLE'] = tf.placeholder(tf.int32, shape=[None], name='FILL_IN_VARIABLE')\n",
        "        subgraph['FILL_IN_VARIABLE'] = tf.placeholder(tf.int32, shape=[None], name='FILL_IN_VARIABLE')\n",
        "\n",
        "        subgraph.update_global_input_mapping({v1: subgraph['FILL_IN_VARIABLE'],\n",
        "                                              v2: subgraph['FILL_IN_VARIABLE']})\n",
        "        \n",
        "    \n",
        "    #TODO: fill in usergraph\n",
        "    @rec.traingraph.usergraph(ins=['FILL_IN_VARIABLE', 'FILL_IN_VARIABLE'], outs=['FILL_IN_VARIABLE'])\n",
        "    @rec.servegraph.usergraph(ins=['FILL_IN_VARIABLE', 'FILL_IN_VARIABLE'], outs=['FILL_IN_VARIABLE'])\n",
        "    def user_graph(subgraph):\n",
        "        _, o1 = LatentFactor(l2_reg=l2_reg_embed,\n",
        "                              shape=[user_dict['gender'], dim_user_embed['gender']],\n",
        "                              id_=subgraph['FILL_IN_VARIABLE'],\n",
        "                              subgraph=subgraph,\n",
        "                              init='normal',\n",
        "                              scope=v1)\n",
        "\n",
        "        _, o2 = LatentFactor(l2_reg=l2_reg_embed,\n",
        "                             shape=[user_dict['geo'], dim_user_embed['geo']],\n",
        "                             id_=subgraph['FILL_IN_VARIABLE'],\n",
        "                             subgraph=subgraph,\n",
        "                             init='normal',\n",
        "                             scope=v2)\n",
        "        subgraph['FILL_IN_VARIABLE'] = tf.concat([o1, o2], axis=1)\n",
        "    \n",
        "    \n",
        "    \n",
        "    #TODO: fill in training interactiongraph\n",
        "    @rec.traingraph.interactiongraph(ins=['FILL_IN_VARIABLE', 'seq_item_vec', 'seq_len', 'label'])\n",
        "    def train_interaction_graph(subgraph):\n",
        "        \n",
        "        MLPSoftmax(user=subgraph['FILL_IN_VARIABLE'],\n",
        "                   item=subgraph['seq_item_vec'],\n",
        "                   seq_len=subgraph['seq_len'],\n",
        "                   max_seq_len=max_seq_len,\n",
        "                   dims=[dim_user_embed['total'] + dim_item_embed['total'], item_dict['id']],\n",
        "                   l2_reg=l2_reg_mlp,\n",
        "                   labels=subgraph['label'],\n",
        "                   dropout=dropout,\n",
        "                   train=True,\n",
        "                   subgraph=subgraph,\n",
        "                   scope='MLPSoftmax')\n",
        "        \n",
        "        \n",
        "\n",
        "     #TODO: fill in serve interactiongraph\n",
        "    @rec.servegraph.interactiongraph(ins=['FILL_IN_VARIABLE', 'seq_item_vec', 'seq_len'])\n",
        "    def serve_interaction_graph(subgraph):\n",
        "\n",
        "        MLPSoftmax(user=subgraph['FILL_IN_VARIABLE'],\n",
        "                   item=subgraph['seq_item_vec'],\n",
        "                   seq_len=subgraph['seq_len'],\n",
        "                   max_seq_len=max_seq_len,\n",
        "                   dims=[dim_user_embed['total'] + dim_item_embed['total'], item_dict['id']],\n",
        "                   l2_reg=l2_reg_mlp,\n",
        "                   train=False,\n",
        "                   subgraph=subgraph,\n",
        "                   scope='MLPSoftmax') \n",
        "    \n",
        "    \n",
        "    #TODO: fill in connector extension\n",
        "    @rec.traingraph.connector.extend\n",
        "    @rec.servegraph.connector.extend\n",
        "    def connect(graph): \n",
        "        graph.usergraph['FILL_IN_VARIABLE'] = graph.inputgraph['FILL_IN_VARIABLE']\n",
        "        graph.usergraph['FILL_IN_VARIABLE'] = graph.inputgraph['FILL_IN_VARIABLE']\n",
        "        graph.interactiongraph['FILL_IN_VARIABLE'] = graph.usergraph['FILL_IN_VARIABLE']\n",
        "\n",
        "    return rec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_hxy8mj0xJQ1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiement\n",
        "We will use the recommender you implemented to run a toy experiement on the LastFM dataset. "
      ]
    },
    {
      "metadata": {
        "id": "z1hg5H5D9-pO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## load lastfm dataset"
      ]
    },
    {
      "metadata": {
        "id": "qd6iP8xyOA5P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "train_data = np.load('lastfm_train.npy')\n",
        "test_data = np.load('lastfm_test.npy')\n",
        "user_feature = np.load('user_feature.npy')\n",
        "\n",
        "total_users = 992   \n",
        "total_items = 14598\n",
        "user_dict = {'gender': 3, \n",
        "             'geo': 67}\n",
        "item_dict = {'id': total_items}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eoox3UQxPCMn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "user_feature[:10], test_data[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jOwNJ4QF-MCx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## preprocessing dataset"
      ]
    },
    {
      "metadata": {
        "id": "olf0fFSTLUrg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from openrec.utils import Dataset\n",
        "\n",
        "train_dataset = Dataset(train_data, total_users, total_items, \n",
        "                        sortby='ts', name='Train')\n",
        "test_dataset = Dataset(test_data, total_users, total_items, \n",
        "                       sortby='ts', name='Test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ralJgDJb-Gn9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## hyperparameters and training parameters"
      ]
    },
    {
      "metadata": {
        "id": "M_17lWG_OEhm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dim_user_embed = {'geo': 40,    # dimension of user geographic embedding\n",
        "                  'gender': 10, # dimension of user gender embedding\n",
        "                   'total': 50} \n",
        "dim_item_embed = {'id': 50, 'total': 50}     # dimension of item embedding\n",
        "\n",
        "\n",
        "max_seq_len = 100       # the maxium length of user's listen history\n",
        "total_iter = int(1e3)   # iterations for training \n",
        "batch_size = 100        # training batch size\n",
        "eval_iter = 100         # iteration of evaluation\n",
        "save_iter = eval_iter   # iteration of saving model   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eJdIPZZf-Qx2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## define sampler\n",
        "We use `YouTubeSampler`  and `YouTubeEvaluationSampler` to sample sequences of training and testing samples. "
      ]
    },
    {
      "metadata": {
        "id": "HzlKCqgyPRyp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from openrec.utils.samplers import YouTubeSampler, YouTubeEvaluationSampler\n",
        "  \n",
        "train_sampler = YouTubeSampler(user_feature=user_feature, \n",
        "                                batch_size=batch_size, \n",
        "                                max_seq_len=max_seq_len, \n",
        "                                dataset=train_dataset, \n",
        "                                num_process=1)\n",
        "test_sampler = YouTubeEvaluationSampler(user_feature=user_feature, \n",
        "                              dataset=test_dataset, \n",
        "                               max_seq_len=max_seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ucqUtRd-YZN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## define evaluator"
      ]
    },
    {
      "metadata": {
        "id": "HzKk_8lW7Wwf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from openrec.utils.evaluators import AUC, Recall\n",
        "\n",
        "auc_evaluator = AUC()\n",
        "recall_evaluator = Recall(recall_at=[100, 200, 300, 400, 500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5w04YyoE-UEm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## define model trainer\n",
        "\n",
        "we used the Vanilla version of the Youtube recommender to train our model."
      ]
    },
    {
      "metadata": {
        "id": "kWX0XpnT7RBE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from openrec import ModelTrainer\n",
        "# from openrec.recommenders import YouTubeRec # load YouTubeRec recommender from openrec library\n",
        "\n",
        "model = Tutorial_YouTubeRec(batch_size=batch_size,\n",
        "                            user_dict=user_dict,\n",
        "                            item_dict=item_dict,\n",
        "                            max_seq_len=max_seq_len,\n",
        "                            dim_item_embed=dim_item_embed,\n",
        "                            dim_user_embed=dim_user_embed,\n",
        "                            save_model_dir='youtube_recommender/',\n",
        "                            train=True, serve=True)\n",
        "\n",
        "model_trainer = ModelTrainer(model=model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FwKd_iFB-thk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## training and testing"
      ]
    },
    {
      "metadata": {
        "id": "q-UffgZW7Rp9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_trainer.train(total_iter=total_iter, \n",
        "                    eval_iter=eval_iter,\n",
        "                    save_iter=save_iter,\n",
        "                    train_sampler=train_sampler,\n",
        "                    eval_samplers=[test_sampler], \n",
        "                    evaluators=[auc_evaluator, recall_evaluator])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K6PP2DVqQXQo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}