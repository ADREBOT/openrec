{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Youtube Recommender example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "UPi-NqzD6TVM"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ylongqi/openrec/blob/master/tutorials/Youtube_Recommender_example.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "jWlLsq0c83u9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img src =\"https://recsys.acm.org/wp-content/uploads/2017/07/recsys-18-small.png\" height=\"40\" /> <font size=\"4\">Recsys 2018 Tutorial</font>\n",
        "</p>\n",
        "<p align=\"center\">\n",
        "  <font size=\"4\"><b>Modularizing Deep Neural Network-Inspired Recommendation Algorithms</b></font>\n",
        "</p>\n",
        "<p align=\"center\">\n",
        "  <font size=\"4\">Hands on: Customizing Deep YouTube Video Recommendation. Youtube example</font>\n",
        "</p>"
      ]
    },
    {
      "metadata": {
        "id": "xXV-a9jCQtvh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# the Youtube Recommender\n",
        "\n",
        "To implement  a model using OpenRec, you will need to first decide how this recommender should be decomposed into subgraphs, i.e., inputgraph, usergraph, itemgraph, interactiongraph and optimizergraph. For example, the training graph of YouTube-Rec can be decomposed as follows.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src =\"https://s3.amazonaws.com/cornell-tech-sdl-openrec/tutorials/youtube_rec_module.png\" height=\"400\" />\n",
        "</p>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* **inputgraph**: user demographis, item consumption history and the groundtruth label.\n",
        "* **usergraph**: extract user-specific latent factor.\n",
        "* **itemgraph**: extract latent factors for items.\n",
        "* **interactiongraph**: uses MLP and softmax to model user-item interactions.\n",
        "\n",
        "After defining subgraphs, their interfaces and connections need to be specified. A sample specification of YouTube-Rec can be as follows.\n",
        "<p align=\"center\">\n",
        "  <img src =\"https://s3.amazonaws.com/cornell-tech-sdl-openrec/tutorials/youtube_rec.png\" height=\"300\" />\n",
        "</p>"
      ]
    },
    {
      "metadata": {
        "id": "fx9f__-hL3C2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install OpenRec and download dataset"
      ]
    },
    {
      "metadata": {
        "id": "iCPtcmnDKsBH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install openrec\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "dataset_prefix = 'http://s3.amazonaws.com/cornell-tech-sdl-openrec'\n",
        "urllib.request.urlretrieve('%s/lastfm/lastfm_test.npy' % dataset_prefix, \n",
        "                   'lastfm_test.npy')\n",
        "urllib.request.urlretrieve('%s/lastfm/lastfm_train.npy' % dataset_prefix, \n",
        "                   'lastfm_train.npy')\n",
        "urllib.request.urlretrieve('%s/lastfm/user_feature.npy' % dataset_prefix, \n",
        "                   'user_feature.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BCp2uMEQKJWK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from openrec.utils.samplers import Sampler\n",
        "\n",
        "def DRRSampler(dataset, batch_size, max_seq_len, user_feature, num_process=5, seed=100, sort=True):\n",
        "\n",
        "    random.seed(seed)\n",
        "    def batch(dataset, user_feature=user_feature, max_seq_len=max_seq_len, batch_size=batch_size):\n",
        "\n",
        "        while True:\n",
        "            input_npy = np.zeros(batch_size, dtype=[('seq_item_id', (np.int32,  max_seq_len)),\n",
        "                                                   ('seq_len', np.int32),\n",
        "                                                   ('label', np.int32),\n",
        "                                                   ('user_gender', np.int32),\n",
        "                                                   ('user_geo', np.int32)])\n",
        "\n",
        "            for ind in range(batch_size):\n",
        "                user_id = random.randint(0, dataset.total_users()-1)\n",
        "                item_list = dataset.get_positive_items(user_id, sort=sort)\n",
        "                while len(item_list) <= 1:\n",
        "                    user_id = random.randint(0, dataset.total_users()-1)\n",
        "                    item_list = dataset.get_positive_items(user_id, sort=sort)\n",
        "                predict_pos = random.randint(1, len(item_list) - 1)\n",
        "                train_items = item_list[max(0, predict_pos-max_seq_len):predict_pos]\n",
        "                pad_train_items = np.zeros(max_seq_len, np.int32)\n",
        "                pad_train_items[:len(train_items)] = train_items\n",
        "                input_npy[ind] = (pad_train_items,\n",
        "                                  len(train_items),\n",
        "                                  item_list[predict_pos],\n",
        "                                  user_feature[user_id]['user_gender'],\n",
        "                                  user_feature[user_id]['user_geo'])\n",
        "            yield input_npy\n",
        "\n",
        "    s = Sampler(dataset=dataset, generate_batch=batch, num_process=num_process)\n",
        "\n",
        "    return s\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "def DRREvaluationSampler(dataset, max_seq_len, user_feature, seed=100, sort=True):\n",
        "\n",
        "    random.seed(seed)\n",
        "    def batch(dataset, user_feature=user_feature, max_seq_len=max_seq_len):\n",
        "\n",
        "        while True:\n",
        "            for user_id in dataset.warm_users():\n",
        "                input_npy = np.zeros(1, dtype=[('seq_item_id', (np.int32,  max_seq_len)),\n",
        "                                               ('seq_len', np.int32),\n",
        "                                               ('user_gender', np.int32),\n",
        "                                               ('user_geo', np.int32)])\n",
        "\n",
        "                item_list = dataset.get_positive_items(user_id, sort=sort)\n",
        "                if len(item_list) <= 1:\n",
        "                    continue\n",
        "                train_items = item_list[-max_seq_len-1:-1]\n",
        "                pad_train_items = np.zeros(max_seq_len, np.int32)\n",
        "                pad_train_items[:len(train_items)] = train_items\n",
        "                input_npy[0] = (pad_train_items,\n",
        "                                len(train_items),\n",
        "                                user_feature[user_id]['user_gender'],\n",
        "                                user_feature[user_id]['user_geo'])\n",
        "                yield [train_items[-1]], input_npy\n",
        "                yield [], []\n",
        "            yield None, None\n",
        "\n",
        "    s = Sampler(dataset=dataset, generate_batch=batch, num_process=1)\n",
        "\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2qnM_4vS6aOw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from openrec.modules.extractions import MultiLayerFC\n",
        "\n",
        "\n",
        "def MLPSoftmax(user, item, seq_len, max_seq_len, dims, subgraph, item_bias=None, \n",
        "               extra=None, l2_reg=None, labels=None, dropout=None, train=None, \n",
        "               scope=None):\n",
        "\n",
        "    with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
        "\n",
        "    \n",
        "        seq_mask = tf.sequence_mask(seq_len, max_seq_len, dtype=tf.float32)\n",
        "        item = tf.reduce_mean(item * tf.expand_dims(seq_mask, axis=2), axis=1)\n",
        "\n",
        "        if user is not None:\n",
        "            in_tensor = tf.concat([user, item], axis=1)\n",
        "        else:\n",
        "            in_tensor = tf.concat([item], axis=1)\n",
        "\n",
        "        if extra is not None:\n",
        "            in_tensor = tf.concat([in_tensor, extra], axis=1)\n",
        "\n",
        "        if train:\n",
        "            logits = MultiLayerFC(in_tensor=in_tensor,\n",
        "                                 dims=dims,\n",
        "                                 subgraph=subgraph,\n",
        "                                 bias_in=True,\n",
        "                                 bias_mid=True,\n",
        "                                 bias_out=False,\n",
        "                                 dropout_mid=dropout,\n",
        "                                 l2_reg=l2_reg,\n",
        "                                 scope='mlp_reg')\n",
        "        else:\n",
        "            logits = MultiLayerFC(in_tensor=in_tensor,\n",
        "                                 dims=dims,\n",
        "                                 subgraph=subgraph,\n",
        "                                 bias_in=True,\n",
        "                                 bias_mid=True,\n",
        "                                 bias_out=False,\n",
        "                                 l2_reg=l2_reg,\n",
        "                                 scope='mlp_reg')\n",
        "\n",
        "        if item_bias is not None:\n",
        "            logits += item_bias\n",
        "\n",
        "        if train:\n",
        "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,\n",
        "                                                           logits=logits)\n",
        "            subgraph.register_global_loss(tf.reduce_mean(loss))\n",
        "        else:\n",
        "            subgraph.register_global_output(tf.squeeze(logits))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xoTTS6s0OJMu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Your task \n",
        "-  understand reuse and extend an exsiting recommender\n",
        "-  fill in the placeholders in the implementation of the `YouTubeRec` function \n",
        "-  successfully run the experimental code with the recommender you just built. "
      ]
    },
    {
      "metadata": {
        "id": "DybVedLuNe_d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from openrec.recommenders import VanillaYouTubeRec\n",
        "from openrec.modules.extractions import LatentFactor\n",
        "import tensorflow as tf\n",
        "\n",
        "def YouTubeRec(batch_size, user_dict, item_dict, dim_user_embed, dim_item_embed, \n",
        "        max_seq_len, l2_reg_embed=None, l2_reg_mlp=None, dropout=None, \n",
        "        init_model_dir=None, save_model_dir='DRR/', train=True, serve=False):\n",
        "\n",
        "  \n",
        "    rec = VanillaYouTubeRec(batch_size=batch_size,\n",
        "                            dim_item_embed=dim_item_embed['id'], \n",
        "                            max_seq_len=max_seq_len, \n",
        "                            total_items=item_dict['id'],\n",
        "                            l2_reg_embed=l2_reg_embed, \n",
        "                            l2_reg_mlp=l2_reg_embed, \n",
        "                            dropout=dropout, \n",
        "                             init_model_dir=init_model_dir,\n",
        "                            save_model_dir=save_model_dir, \n",
        "                            train=train, \n",
        "                            serve=serve)\n",
        "    \n",
        "\n",
        "    #TODO: fill in variables v1 and v2\n",
        "    v1 = 'FILL_IN_VARIABLE_NAME'\n",
        "    v2 = 'FILL_IN_VARIABLE_NAME'\n",
        "    @rec.traingraph.inputgraph.extend(outs=[v1, v2])\n",
        "    def add_feature(subgraph):\n",
        "        subgraph[v1] = tf.placeholder(tf.int32, shape=[batch_size], name=v1)\n",
        "        subgraph[v2] = tf.placeholder(tf.int32, shape=[batch_size], name=v2)\n",
        "       \n",
        "        subgraph.update_global_input_mapping({v1: subgraph[v1],\n",
        "                                              v2: subgraph[v2]\n",
        "                                             })\n",
        "\n",
        "        \n",
        "    #TODO: fill in variables v1 and v2\n",
        "    v1 = 'FILL_IN_VARIABLE_NAME'\n",
        "    v2 = 'FILL_IN_VARIABLE_NAME'\n",
        "    @rec.servegraph.inputgraph.extend(outs=[v1, v2])\n",
        "    def add_feature(subgraph):\n",
        "        subgraph[v1] = tf.placeholder(tf.int32, shape=[None], name=v1)\n",
        "        subgraph[v2] = tf.placeholder(tf.int32, shape=[None], name=v2)\n",
        "\n",
        "        subgraph.update_global_input_mapping({v1: subgraph[v1],\n",
        "                                              v2: subgraph[v2]})\n",
        "        \n",
        "    \n",
        "    #TODO: fill in variables v1, v2, v3\n",
        "    v1 = 'FILL_IN_VARIABLE_NAME'\n",
        "    v2 = 'FILL_IN_VARIABLE_NAME'\n",
        "    v3 = 'FILL_IN_VARIABLE_NAME'\n",
        "    @rec.traingraph.usergraph(ins=[v1, v2], outs=[v3])\n",
        "    @rec.servegraph.usergraph(ins=[v1, v2], outs=[v3])\n",
        "    def user_graph(subgraph):\n",
        "        _, o1 = LatentFactor(l2_reg=l2_reg_embed,\n",
        "                              shape=[user_dict[v1], dim_user_embed[v1]],\n",
        "                              id_=subgraph[v1],\n",
        "                              subgraph=subgraph,\n",
        "                              init='normal',\n",
        "                              scope=v1)\n",
        "\n",
        "        _, o2 = LatentFactor(l2_reg=l2_reg_embed,\n",
        "                             shape=[user_dict[v2], dim_user_embed[v2]],\n",
        "                             id_=subgraph[v2],\n",
        "                             subgraph=subgraph,\n",
        "                             init='normal',\n",
        "                             scope=v2)\n",
        "        subgraph[v3] = tf.concat([o1, o2], axis=1)\n",
        "    \n",
        "    \n",
        "    \n",
        "    #TODO: fill in variables v1\n",
        "    v1 = 'FILL_IN_VARIABLE_NAME'\n",
        "    @rec.traingraph.interactiongraph(ins=[v1, 'seq_vec', 'seq_len', 'label'])\n",
        "    def train_interaction_graph(subgraph):\n",
        "        dim = sum(list(dim_user_embed.values())) + sum(list(dim_item_embed.values()))\n",
        "        MLPSoftmax(user=subgraph[v1],\n",
        "                   item=subgraph['seq_vec'],\n",
        "                   seq_len=subgraph['seq_len'],\n",
        "                   max_seq_len=max_seq_len,\n",
        "                   dims=[dim, item_dict['item_id']],\n",
        "                   l2_reg=l2_reg_mlp,\n",
        "                   labels=subgraph['label'],\n",
        "                   dropout=dropout,\n",
        "                   train=True,\n",
        "                   subgraph=subgraph,\n",
        "                   scope='MLPSoftmax'\n",
        "                  )\n",
        "        \n",
        "        \n",
        "\n",
        "    #TODO: fill in variables v1\n",
        "    v1 = 'FILL_IN_VARIABLE_NAME'\n",
        "    @rec.servegraph.interactiongraph(ins=[v1, 'seq_vec', 'seq_len'])\n",
        "    def serve_interaction_graph(subgraph):\n",
        "        dim = sum(list(dim_user_embed.values())) + sum(list(dim_item_embed.values()))\n",
        "        MLPSoftmax(user=subgraph[v1],\n",
        "                   item=subgraph['seq_vec'],\n",
        "                   seq_len=subgraph['seq_len'],\n",
        "                   max_seq_len=max_seq_len,\n",
        "                   dims=[dim, item_dict['item_id']],\n",
        "                   l2_reg=l2_reg_mlp,\n",
        "                   train=False,\n",
        "                   subgraph=subgraph,\n",
        "                   scope='MLPSoftmax') \n",
        "    \n",
        "    \n",
        "    #TODO: fill in variables v1, v2, v3\n",
        "    v1 = 'FILL_IN_VARIABLE_NAME'\n",
        "    v2 = 'FILL_IN_VARIABLE_NAME'\n",
        "    v3 = 'FILL_IN_VARIABLE_NAME'\n",
        "    @rec.traingraph.connector.extend\n",
        "    @rec.servegraph.connector.extend\n",
        "    def connect(graph): \n",
        "        graph.usergraph[v1] = graph.inputgraph[v1]\n",
        "        graph.usergraph[v2] = graph.inputgraph[v2]\n",
        "        graph.interactiongraph[v3] = graph.usergraph[v3]\n",
        "\n",
        "    return rec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_hxy8mj0xJQ1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiement\n",
        "We will use the recommender you implemented to run a toy experiement on the LastFM dataset. "
      ]
    },
    {
      "metadata": {
        "id": "z1hg5H5D9-pO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## load lastfm dataset"
      ]
    },
    {
      "metadata": {
        "id": "qd6iP8xyOA5P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "train_data = np.load('lastfm_train.npy')\n",
        "test_data = np.load('lastfm_test.npy')\n",
        "user_feature = np.load('user_feature.npy')\n",
        "\n",
        "total_users = 992   \n",
        "total_items = 14598\n",
        "user_dict = {'gender': 3, \n",
        "             'geo': 67}\n",
        "item_dict = {'id': total_items}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eoox3UQxPCMn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "user_feature[:10], test_data[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jOwNJ4QF-MCx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## preprocessing dataset"
      ]
    },
    {
      "metadata": {
        "id": "olf0fFSTLUrg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from openrec.utils import Dataset\n",
        "\n",
        "train_dataset = Dataset(train_data, total_users, total_items, \n",
        "                        sortby='ts', name='Train')\n",
        "test_dataset = Dataset(test_data, total_users, total_items, \n",
        "                       sortby='ts', name='Test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ralJgDJb-Gn9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## hyperparameters and training parameters"
      ]
    },
    {
      "metadata": {
        "id": "M_17lWG_OEhm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dim_user_embed = {'geo': 40,    # dimension of user geographic embedding\n",
        "                  'gender': 10, # dimension of user gender embedding\n",
        "                   'total': 50} \n",
        "dim_item_embed = {'id': 50, 'total': 50}     # dimension of item embedding\n",
        "\n",
        "\n",
        "max_seq_len = 100       # the maxium length of user's listen history\n",
        "total_iter = int(1e3)   # iterations for training \n",
        "batch_size = 100        # training batch size\n",
        "eval_iter = 100         # iteration of evaluation\n",
        "save_iter = eval_iter   # iteration of saving model   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eJdIPZZf-Qx2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## define sampler\n",
        "We use `DRRSampler`  and `DRREvaluationSampler` to sample sequences of training and testing samples. "
      ]
    },
    {
      "metadata": {
        "id": "HzlKCqgyPRyp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from openrec.utils.samplers import YouTubeSampler, YouTubeEvaluationSampler\n",
        "  \n",
        "train_sampler = YouTubeSampler(user_feature=user_feature, \n",
        "                                batch_size=batch_size, \n",
        "                                max_seq_len=max_seq_len, \n",
        "                                dataset=train_dataset, \n",
        "                                num_process=1)\n",
        "test_sampler = YouTubeEvaluationSampler(user_feature=user_feature, \n",
        "                              dataset=test_dataset, \n",
        "                               max_seq_len=max_seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ucqUtRd-YZN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## define evaluator"
      ]
    },
    {
      "metadata": {
        "id": "HzKk_8lW7Wwf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from openrec.utils.evaluators import AUC, Recall\n",
        "\n",
        "auc_evaluator = AUC()\n",
        "recall_evaluator = Recall(recall_at=[100, 200, 300, 400, 500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5w04YyoE-UEm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## define model trainer\n",
        "\n",
        "we used the Vanilla version of the Youtube recommender to train our model."
      ]
    },
    {
      "metadata": {
        "id": "kWX0XpnT7RBE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from openrec import ModelTrainer\n",
        "from openrec.recommenders import YouTubeRec\n",
        "\n",
        "model = YouTubeRec(batch_size=batch_size,\n",
        "                  user_dict=user_dict,\n",
        "                  item_dict=item_dict,\n",
        "                  max_seq_len=max_seq_len,\n",
        "                  dim_item_embed=dim_item_embed,\n",
        "                  dim_user_embed=dim_user_embed,\n",
        "                  save_model_dir='youtube_recommender/',\n",
        "                  train=True, serve=True)\n",
        "\n",
        "model_trainer = ModelTrainer(model=model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FwKd_iFB-thk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## training and testing"
      ]
    },
    {
      "metadata": {
        "id": "q-UffgZW7Rp9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_trainer.train(total_iter=total_iter, \n",
        "                    eval_iter=eval_iter,\n",
        "                    save_iter=save_iter,\n",
        "                    train_sampler=train_sampler,\n",
        "                    eval_samplers=[test_sampler], \n",
        "                    evaluators=[auc_evaluator, recall_evaluator])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K6PP2DVqQXQo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}